{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出单元激活函数\n",
    "def softmax(x):\n",
    "    x = np.array(x)\n",
    "    max_x = np.max(x)\n",
    "    return np.exp(x-max_x) / np.sum(np.exp(x-max_x))\n",
    " \n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    " \n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM(object):\n",
    "    def __init__(self, data_dim, hidden_dim=100):\n",
    "        # data_dim: 词向量维度，即词典长度; hidden_dim: 隐单元维度\n",
    "        self.data_dim = data_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        # 初始化权重向量 \n",
    "        self.whi, self.wxi, self.bi = self._init_wh_wx()\n",
    "        \n",
    "        print(self.wxi.shape)\n",
    "        self.whf, self.wxf, self.bf = self._init_wh_wx()                           \n",
    "        self.who, self.wxo, self.bo = self._init_wh_wx()\n",
    "        self.wha, self.wxa, self.ba = self._init_wh_wx()\n",
    "        self.wy, self.by = np.random.uniform(-np.sqrt(1.0/self.hidden_dim), np.sqrt(1.0/self.hidden_dim), \n",
    "                                   (self.data_dim, self.hidden_dim)), \\\n",
    "                           np.random.uniform(-np.sqrt(1.0/self.hidden_dim), np.sqrt(1.0/self.hidden_dim), \n",
    "                                   (self.data_dim, 1))\n",
    " \n",
    "    # 初始化 wh, wx, b\n",
    "    def _init_wh_wx(self):\n",
    "        wh = np.random.uniform(-np.sqrt(1.0/self.hidden_dim), np.sqrt(1.0/self.hidden_dim), \n",
    "                                   (self.hidden_dim, self.hidden_dim))\n",
    "        wx = np.random.uniform(-np.sqrt(1.0/self.data_dim), np.sqrt(1.0/self.data_dim), \n",
    "                                   (self.hidden_dim, self.data_dim))\n",
    "        b = np.random.uniform(-np.sqrt(1.0/self.data_dim), np.sqrt(1.0/self.data_dim), \n",
    "                                   (self.hidden_dim, 1))\n",
    " \n",
    "        return wh, wx, b\n",
    " \n",
    "    # 初始化各个状态向量\n",
    "    def _init_s(self, T):\n",
    "        iss = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # input gate\n",
    "        fss = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # forget gate\n",
    "        oss = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # output gate\n",
    "        ass = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # current inputstate\n",
    "        hss = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # hidden state\n",
    "        css = np.array([np.zeros((self.hidden_dim, 1))] * (T + 1))  # cell state\n",
    "        ys = np.array([np.zeros((self.data_dim, 1))] * T)    # output value\n",
    " \n",
    "        return {'iss': iss, 'fss': fss, 'oss': oss, \n",
    "                'ass': ass, 'hss': hss, 'css': css, \n",
    "                'ys': ys}\n",
    "     \n",
    "    def plot_loss():\n",
    "        x = np.arange(0,len(self.losses))\n",
    "        plt.plot(x,losses)\n",
    "        plt.show()\n",
    "        \n",
    "    # 前向传播，单个x\n",
    "    def forward(self, x):\n",
    "        # 向量时间长度\n",
    "        T = len(x)        \n",
    "        # 初始化各个状态向量\n",
    "        stats = self._init_s(T)               \n",
    " \n",
    "        for t in range(T):\n",
    "            # 前一时刻隐藏状态\n",
    "            ht_pre = np.array(stats['hss'][t-1]).reshape(-1, 1)\n",
    " \n",
    "            # input gate\n",
    "            stats['iss'][t] = self._cal_gate(self.whi, self.wxi, self.bi, ht_pre, x[t], sigmoid)\n",
    "            # forget gate\n",
    "            stats['fss'][t] = self._cal_gate(self.whf, self.wxf, self.bf, ht_pre, x[t], sigmoid)\n",
    "            # output gate\n",
    "            stats['oss'][t] = self._cal_gate(self.who, self.wxo, self.bo, ht_pre, x[t], sigmoid)\n",
    "            # current inputstate\n",
    "            stats['ass'][t] = self._cal_gate(self.wha, self.wxa, self.ba, ht_pre, x[t], tanh)\n",
    " \n",
    "            # cell state, ct = ft * ct_pre + it * at\n",
    "            stats['css'][t] = stats['fss'][t] * stats['css'][t-1] + stats['iss'][t] * stats['ass'][t]            \n",
    "            # hidden state, ht = ot * tanh(ct)\n",
    "            stats['hss'][t] = stats['oss'][t] * tanh(stats['css'][t])\n",
    " \n",
    "            # output value, yt = softmax(self.wy.dot(ht) + self.by)\n",
    "            stats['ys'][t] = softmax(self.wy.dot(stats['hss'][t]) + self.by)\n",
    " \n",
    "        return stats\n",
    " \n",
    "    # 计算各个门的输出\n",
    "    def _cal_gate(self, wh, wx, b, ht_pre, x, activation):\n",
    "        return activation(wh.dot(ht_pre) + wx[:, x].reshape(-1,1) + b)\n",
    " \n",
    "    # 预测输出，单个x    \n",
    "    def predict(self, x):\n",
    "        stats = self.forward(x)\n",
    "        pre_y = np.argmax(stats['ys'].reshape(len(x), -1), axis=1)         \n",
    "        return pre_y\n",
    " \n",
    "    # 计算损失， softmax交叉熵损失函数， (x,y)为多个样本\n",
    "    def loss(self, x, y):\n",
    "        cost = 0        \n",
    "        for i in range(len(y)):\n",
    "            stats = self.forward(x[i])\n",
    "            # 取出 y[i] 中每一时刻对应的预测值\n",
    "            pre_yi = stats['ys'][range(len(y[i])), y[i]]\n",
    "            cost -= np.sum(np.log(pre_yi))\n",
    " \n",
    "        # 统计所有y中词的个数, 计算平均损失\n",
    "        N = np.sum([len(yi) for yi in y])\n",
    "        ave_loss = cost / N\n",
    " \n",
    "        return ave_loss\n",
    " \n",
    "     # 初始化偏导数 dwh, dwx, db\n",
    "    def _init_wh_wx_grad(self):\n",
    "        dwh = np.zeros(self.whi.shape)\n",
    "        dwx = np.zeros(self.wxi.shape)\n",
    "        db = np.zeros(self.bi.shape)\n",
    " \n",
    "        return dwh, dwx, db\n",
    " \n",
    "    # 求梯度, (x,y)为一个样本\n",
    "    def bptt(self, x, y):\n",
    "        dwhi, dwxi, dbi = self._init_wh_wx_grad()\n",
    "        dwhf, dwxf, dbf = self._init_wh_wx_grad()                           \n",
    "        dwho, dwxo, dbo = self._init_wh_wx_grad()\n",
    "        dwha, dwxa, dba = self._init_wh_wx_grad()\n",
    "        dwy, dby = np.zeros(self.wy.shape), np.zeros(self.by.shape)\n",
    " \n",
    "        # 初始化 delta_ct，因为后向传播过程中，此值需要累加\n",
    "        delta_ct = np.zeros((self.hidden_dim, 1))\n",
    " \n",
    "        # 前向计算\n",
    "        stats = self.forward(x)\n",
    "        # 目标函数对输出 y 的偏导数\n",
    "        delta_o = stats['ys']\n",
    "        delta_o[np.arange(len(y)), y] -= 1\n",
    " \n",
    "        for t in np.arange(len(y))[::-1]:\n",
    "            # 输出层wy, by的偏导数，由于所有时刻的输出共享输出权值矩阵，故所有时刻累加\n",
    "            dwy += delta_o[t].dot(stats['hss'][t].reshape(1, -1))  \n",
    "            dby += delta_o[t]\n",
    " \n",
    "            # 目标函数对隐藏状态的偏导数\n",
    "            delta_ht = self.wy.T.dot(delta_o[t])\n",
    " \n",
    "            # 各个门及状态单元的偏导数\n",
    "            delta_ot = delta_ht * tanh(stats['css'][t])\n",
    "            delta_ct += delta_ht * stats['oss'][t] * (1-tanh(stats['css'][t])**2)\n",
    "            delta_it = delta_ct * stats['ass'][t]\n",
    "            delta_ft = delta_ct * stats['css'][t-1]\n",
    "            delta_at = delta_ct * stats['iss'][t]\n",
    " \n",
    "            delta_at_net = delta_at * (1-stats['ass'][t]**2)\n",
    "            delta_it_net = delta_it * stats['iss'][t] * (1-stats['iss'][t])\n",
    "            delta_ft_net = delta_ft * stats['fss'][t] * (1-stats['fss'][t])\n",
    "            delta_ot_net = delta_ot * stats['oss'][t] * (1-stats['oss'][t])\n",
    " \n",
    "            # 更新各权重矩阵的偏导数，由于所有时刻共享权值，故所有时刻累加\n",
    "            dwhf, dwxf, dbf = self._cal_grad_delta(dwhf, dwxf, dbf, delta_ft_net, stats['hss'][t-1], x[t])                              \n",
    "            dwhi, dwxi, dbi = self._cal_grad_delta(dwhi, dwxi, dbi, delta_it_net, stats['hss'][t-1], x[t])                              \n",
    "            dwha, dwxa, dba = self._cal_grad_delta(dwha, dwxa, dba, delta_at_net, stats['hss'][t-1], x[t])            \n",
    "            dwho, dwxo, dbo = self._cal_grad_delta(dwho, dwxo, dbo, delta_ot_net, stats['hss'][t-1], x[t])\n",
    " \n",
    "        return [dwhf, dwxf, dbf, \n",
    "                dwhi, dwxi, dbi, \n",
    "                dwha, dwxa, dba, \n",
    "                dwho, dwxo, dbo, \n",
    "                dwy, dby]\n",
    " \n",
    "    # 更新各权重矩阵的偏导数            \n",
    "    def _cal_grad_delta(self, dwh, dwx, db, delta_net, ht_pre, x):\n",
    "        dwh += delta_net * ht_pre\n",
    "        dwx += delta_net * x\n",
    "        db += delta_net\n",
    " \n",
    "        return dwh, dwx, db\n",
    " \n",
    "    # 计算梯度, (x,y)为一个样本\n",
    "    def sgd_step(self, x, y, learning_rate):\n",
    "        dwhf, dwxf, dbf, \\\n",
    "        dwhi, dwxi, dbi, \\\n",
    "        dwha, dwxa, dba, \\\n",
    "        dwho, dwxo, dbo, \\\n",
    "        dwy, dby = self.bptt(x, y)\n",
    " \n",
    "        # 更新权重矩阵\n",
    "        self.whf, self.wxf, self.bf = self._update_wh_wx(learning_rate, self.whf, self.wxf, self.bf, dwhf, dwxf, dbf)\n",
    "        self.whi, self.wxi, self.bi = self._update_wh_wx(learning_rate, self.whi, self.wxi, self.bi, dwhi, dwxi, dbi)\n",
    "        self.wha, self.wxa, self.ba = self._update_wh_wx(learning_rate, self.wha, self.wxa, self.ba, dwha, dwxa, dba)\n",
    "        self.who, self.wxo, self.bo = self._update_wh_wx(learning_rate, self.who, self.wxo, self.bo, dwho, dwxo, dbo)\n",
    " \n",
    "        self.wy, self.by = self.wy - learning_rate * dwy, self.by - learning_rate * dby\n",
    " \n",
    "    # 更新权重矩阵\n",
    "    def _update_wh_wx(self, learning_rate, wh, wx, b, dwh, dwx, db):\n",
    "        wh -= learning_rate * dwh\n",
    "        wx -= learning_rate * dwx\n",
    "        b -= learning_rate * db\n",
    " \n",
    "        return wh, wx, b\n",
    "    # 训练 LSTM\n",
    "    def train(self, X_train, y_train, learning_rate=0.005, n_epoch=5):\n",
    "        losses = []\n",
    "        num_examples = 0\n",
    " \n",
    "        for epoch in range(n_epoch):   \n",
    "            for i in range(len(y_train)):\n",
    "                self.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "                num_examples += 1\n",
    "                if i%200 ==0:\n",
    "                    \n",
    "                    loss = self.loss(X_train, y_train)\n",
    "                    print ('-'*8+'epoch {0} batch = {1}: loss = {2}'.format(epoch+1, i , loss)+'-'*8)\n",
    "                    losses.append(loss)\n",
    "\n",
    "            loss = self.loss(X_train, y_train)\n",
    "            losses.append(loss)\n",
    "            print ('-'*15+'epoch {0}: loss = {1}'.format(epoch+1, loss)+'-'*15)\n",
    "            if len(losses) > 1 and losses[-1] > losses[-2]:\n",
    "                learning_rate *= 0.5\n",
    "                print( 'decrease learning_rate to', learning_rate)\n",
    "        self.losses = losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n",
      "16\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 最多8位二进制\n",
    "BINARY_DIM = 8\n",
    "\n",
    "# 将整数表示成为binary_dim位的二进制数，高位用0补齐\n",
    "def int_2_binary(number, binary_dim):\n",
    "    binary_list = list(map(lambda x: int(x), bin(number)[2:]))\n",
    "    number_dim = len(binary_list)\n",
    "    result_list = [0]*(binary_dim-number_dim)+binary_list\n",
    "    return result_list\n",
    "\n",
    "# 将一个二进制数组转为整数\n",
    "def binary2int(binary_array):\n",
    "    out = 0\n",
    "    for index, x in enumerate(reversed(binary_array)):\n",
    "        out += x * pow(2, index)\n",
    "    return out\n",
    "\n",
    "# 将[0,2**BINARY_DIM)所有数表示成二进制\n",
    "binary = np.array([int_2_binary(x, BINARY_DIM) for x in range(2**BINARY_DIM)])\n",
    "# print(binary)\n",
    "\n",
    "# 样本的输入向量和输出向量\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(binary.shape[0]):\n",
    "    for j in range(binary.shape[0]):\n",
    "        dataX.append(np.append(binary[i], binary[j]))\n",
    "        dataY.append(int_2_binary(i+j, BINARY_DIM+1))\n",
    "\n",
    "print(len(dataX)) ## 2**16 个样本\n",
    "print(len(dataX[0]))\n",
    "print(len(dataY[0]))\n",
    "# print(dataY)\n",
    "\n",
    "# 重新特征X和目标变量Y数组，适应LSTM模型的输入和输出\n",
    "X = np.reshape(dataX, (len(dataX), 2*BINARY_DIM, 1))\n",
    "# print(X.shape)\n",
    "Y = np.array(dataY)\n",
    "# print(dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用keras实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras import losses\n",
    "from keras.utils import plot_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65536/65536 [==============================] - 44s - loss: 0.2350 - acc: 0.5409    \n",
      "Epoch 2/5\n",
      "65536/65536 [==============================] - 42s - loss: 0.1907 - acc: 0.8422    \n",
      "Epoch 3/5\n",
      "65536/65536 [==============================] - 42s - loss: 0.1457 - acc: 0.8435    \n",
      "Epoch 4/5\n",
      "65536/65536 [==============================] - 42s - loss: 0.1315 - acc: 0.7942    \n",
      "Epoch 5/5\n",
      "65536/65536 [==============================] - 42s - loss: 0.1248 - acc: 0.7291    \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义LSTM模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.compile(loss=losses.mean_squared_error, optimizer='adam',metrics=['accuracy'])\n",
    "#创建一个实例history\n",
    "history = LossHistory()\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# plot model\n",
    "plot_model(model, to_file=r'./model.png', show_shapes=True)\n",
    "# train model\n",
    "epochs = 5\n",
    "model.fit(X, Y, epochs=epochs, batch_size=128,callbacks=[history])\n",
    "history.loss_plot('batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型\n",
    "\n",
    "<img src=\"model1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "[1 0 1 1 0 0 1 0]: 178\n",
      "[0 0 0 0 1 0 1 1]: 11\n",
      "[0 1 0 1 1 0 1 0 1]: 181\n",
      "==============================\n",
      "[0 0 1 0 0 1 0 1]: 37\n",
      "[1 1 0 0 0 0 1 1]: 195\n",
      "[0 1 1 1 1 1 1 1 0]: 254\n",
      "==============================\n",
      "[0 1 0 0 1 1 1 1]: 79\n",
      "[0 1 0 0 0 1 0 1]: 69\n",
      "[0 1 0 0 1 0 1 0 0]: 148\n",
      "==============================\n",
      "[1 1 0 1 1 0 1 1]: 219\n",
      "[1 1 0 1 0 0 0 1]: 209\n",
      "[1 1 0 1 1 1 0 0 0]: 440\n",
      "==============================\n",
      "[1 0 1 1 0 0 1 1]: 179\n",
      "[0 1 1 1 0 1 0 0]: 116\n",
      "[1 0 0 1 1 0 0 0 1]: 305\n",
      "==============================\n",
      "[1 0 1 0 0 1 1 0]: 166\n",
      "[1 1 0 0 1 0 0 0]: 200\n",
      "[1 0 1 1 0 1 0 1 0]: 362\n",
      "==============================\n",
      "[0 1 0 1 0 1 1 1]: 87\n",
      "[1 1 0 1 0 1 1 1]: 215\n",
      "[1 0 0 1 1 0 1 0 0]: 308\n",
      "==============================\n",
      "[1 1 1 0 0 0 0 1]: 225\n",
      "[1 0 0 1 0 1 0 1]: 149\n",
      "[1 0 1 1 1 1 0 0 0]: 376\n",
      "==============================\n",
      "[1 1 0 1 1 1 1 1]: 223\n",
      "[0 0 1 1 1 1 0 0]: 60\n",
      "[1 0 0 0 1 0 1 0 1]: 277\n",
      "==============================\n",
      "[1 1 0 1 1 1 1 0]: 222\n",
      "[1 1 0 0 0 1 1 0]: 198\n",
      "[1 1 0 0 1 0 0 0 0]: 400\n",
      "==============================\n",
      "[0 0 1 0 0 1 0 1]: 37\n",
      "[1 0 1 1 0 1 0 1]: 181\n",
      "[0 1 1 0 1 0 1 1 0]: 214\n",
      "==============================\n",
      "[1 0 0 0 0 1 1 1]: 135\n",
      "[0 1 0 0 0 1 0 0]: 68\n",
      "[0 1 1 0 0 0 1 0 1]: 197\n",
      "==============================\n",
      "[0 0 0 0 1 1 1 1]: 15\n",
      "[1 1 1 1 1 0 0 1]: 249\n",
      "[1 0 0 0 0 0 1 0 0]: 260\n",
      "==============================\n",
      "[0 1 1 0 0 1 1 1]: 103\n",
      "[1 1 1 1 0 1 1 0]: 246\n",
      "[1 0 1 0 0 1 0 1 1]: 331\n",
      "==============================\n",
      "[0 0 1 0 0 1 1 0]: 38\n",
      "[0 1 0 1 0 0 1 1]: 83\n",
      "[0 0 1 1 1 1 1 0 1]: 125\n",
      "==============================\n",
      "[0 1 0 1 0 1 0 1]: 85\n",
      "[1 1 0 0 1 1 1 1]: 207\n",
      "[1 0 0 1 1 0 0 0 0]: 304\n",
      "==============================\n",
      "[0 1 1 0 1 0 1 1]: 107\n",
      "[0 0 1 1 1 1 0 0]: 60\n",
      "[0 1 0 0 1 0 1 0 1]: 149\n",
      "==============================\n",
      "[0 1 1 0 1 0 0 0]: 104\n",
      "[1 1 1 0 1 1 1 0]: 238\n",
      "[1 0 1 0 0 1 1 1 0]: 334\n",
      "==============================\n",
      "[1 1 1 0 0 1 1 1]: 231\n",
      "[0 1 1 0 1 1 1 0]: 110\n",
      "[1 0 1 0 0 1 1 1 1]: 335\n",
      "==============================\n",
      "[1 1 0 0 0 0 0 1]: 193\n",
      "[0 1 0 1 0 0 1 1]: 83\n",
      "[1 0 0 0 1 0 0 0 0]: 272\n",
      "==============================\n",
      "[1 0 1 1 0 1 0 0]: 180\n",
      "[0 1 1 1 1 1 1 0]: 126\n",
      "[1 0 0 1 1 0 0 1 0]: 306\n",
      "==============================\n",
      "[1 0 0 0 1 1 0 0]: 140\n",
      "[1 0 0 1 0 1 1 0]: 150\n",
      "[1 0 0 1 1 0 0 1 0]: 306\n",
      "==============================\n",
      "[0 1 1 1 0 1 1 0]: 118\n",
      "[1 1 1 0 1 1 1 0]: 238\n",
      "[1 0 1 0 1 0 1 0 0]: 340\n",
      "==============================\n",
      "[1 1 1 1 1 0 0 1]: 249\n",
      "[0 0 0 1 1 0 1 1]: 27\n",
      "[1 0 0 0 1 0 0 0 0]: 272\n",
      "==============================\n",
      "[1 0 1 1 1 1 1 1]: 191\n",
      "[0 0 1 0 1 1 0 0]: 44\n",
      "[0 1 1 1 0 0 1 0 1]: 229\n",
      "==============================\n",
      "[0 0 0 0 1 0 0 1]: 9\n",
      "[0 1 0 1 1 1 0 1]: 93\n",
      "[0 0 1 0 1 1 0 1 0]: 90\n",
      "==============================\n",
      "[1 1 0 0 1 1 0 1]: 205\n",
      "[0 1 0 1 1 0 1 0]: 90\n",
      "[1 0 0 1 1 0 1 0 1]: 309\n",
      "==============================\n",
      "[1 0 0 1 1 0 1 0]: 154\n",
      "[0 1 0 1 1 0 0 1]: 89\n",
      "[0 1 1 1 1 0 1 1 1]: 247\n",
      "==============================\n",
      "[1 0 0 1 0 1 1 0]: 150\n",
      "[0 0 0 1 1 1 1 0]: 30\n",
      "[0 1 0 1 1 0 1 0 0]: 180\n",
      "==============================\n",
      "[1 1 0 0 0 1 0 0]: 196\n",
      "[1 1 1 0 1 1 1 0]: 238\n",
      "[1 1 0 0 0 0 0 1 0]: 386\n",
      "==============================\n",
      "[1 0 0 1 0 0 0 1]: 145\n",
      "[1 1 1 1 0 0 1 0]: 242\n",
      "[1 1 0 0 1 1 0 1 1]: 411\n",
      "==============================\n",
      "[0 1 1 0 1 1 1 0]: 110\n",
      "[0 0 1 1 1 0 1 1]: 59\n",
      "[0 1 0 1 1 0 1 0 1]: 181\n",
      "==============================\n",
      "[0 0 1 1 0 0 0 0]: 48\n",
      "[0 1 0 0 0 1 0 1]: 69\n",
      "[0 0 1 1 1 1 1 0 1]: 125\n",
      "==============================\n",
      "[0 1 0 1 1 0 1 1]: 91\n",
      "[0 1 1 0 1 0 0 0]: 104\n",
      "[0 1 0 1 1 0 1 0 1]: 181\n",
      "==============================\n",
      "[0 0 0 1 1 0 1 1]: 27\n",
      "[0 1 0 1 0 1 1 1]: 87\n",
      "[0 0 1 1 1 1 1 1 0]: 126\n",
      "==============================\n",
      "[1 1 1 0 1 1 1 1]: 239\n",
      "[0 0 0 0 0 0 0 1]: 1\n",
      "[0 1 1 1 1 0 1 0 0]: 244\n",
      "==============================\n",
      "[0 1 0 0 1 0 0 0]: 72\n",
      "[1 1 1 0 1 1 0 1]: 237\n",
      "[1 0 0 1 1 1 1 0 1]: 317\n",
      "==============================\n",
      "[1 0 0 1 1 1 0 0]: 156\n",
      "[1 0 1 1 1 1 1 1]: 191\n",
      "[1 0 1 0 0 0 0 1 1]: 323\n",
      "==============================\n",
      "[1 0 1 1 1 1 0 1]: 189\n",
      "[1 1 1 0 1 0 0 0]: 232\n",
      "[1 1 0 0 1 1 0 0 1]: 409\n",
      "==============================\n",
      "[0 1 1 1 0 1 0 0]: 116\n",
      "[1 1 0 0 1 1 0 1]: 205\n",
      "[1 0 1 1 1 0 0 0 1]: 369\n",
      "==============================\n",
      "[1 1 1 0 1 0 1 0]: 234\n",
      "[0 0 0 1 0 1 0 0]: 20\n",
      "[0 1 1 1 1 0 1 1 0]: 246\n",
      "==============================\n",
      "[0 0 0 0 0 0 0 0]: 0\n",
      "[0 1 1 0 1 1 1 0]: 110\n",
      "[0 0 1 1 1 1 1 1 0]: 126\n",
      "==============================\n",
      "[1 0 1 1 0 1 0 0]: 180\n",
      "[1 1 1 0 1 0 1 0]: 234\n",
      "[1 1 0 0 0 1 1 1 0]: 398\n",
      "==============================\n",
      "[0 1 1 1 1 0 1 0]: 122\n",
      "[1 0 1 1 1 0 0 1]: 185\n",
      "[1 0 0 1 1 1 1 1 1]: 319\n",
      "==============================\n",
      "[1 0 1 1 0 0 0 1]: 177\n",
      "[1 0 0 1 0 1 0 1]: 149\n",
      "[1 0 1 0 0 1 0 0 0]: 328\n",
      "==============================\n",
      "[1 1 1 0 1 1 0 1]: 237\n",
      "[1 0 1 1 1 1 0 0]: 188\n",
      "[1 1 0 1 1 1 0 0 1]: 441\n",
      "==============================\n",
      "[0 0 1 1 0 0 0 1]: 49\n",
      "[1 0 1 1 0 0 1 0]: 178\n",
      "[0 1 1 1 1 0 1 1 1]: 247\n",
      "==============================\n",
      "[0 1 1 1 1 0 0 1]: 121\n",
      "[1 1 1 0 0 0 0 0]: 224\n",
      "[1 0 1 0 0 1 1 1 1]: 335\n",
      "==============================\n",
      "[1 0 0 0 1 0 0 0]: 136\n",
      "[0 1 1 1 0 0 1 0]: 114\n",
      "[0 1 1 1 1 0 0 1 0]: 242\n",
      "==============================\n",
      "[1 1 0 0 0 1 1 0]: 198\n",
      "[1 1 1 1 1 0 0 0]: 248\n",
      "[1 1 0 0 0 0 0 1 0]: 386\n",
      "==============================\n",
      "[1 0 1 0 1 0 0 1]: 169\n",
      "[0 0 1 1 1 1 1 1]: 63\n",
      "[0 1 1 1 1 0 0 1 0]: 242\n",
      "==============================\n",
      "[0 0 0 1 1 0 0 1]: 25\n",
      "[0 0 1 1 0 1 1 0]: 54\n",
      "[0 0 1 0 1 1 0 1 1]: 91\n",
      "==============================\n",
      "[0 1 1 1 1 0 0 1]: 121\n",
      "[0 1 0 0 1 0 0 1]: 73\n",
      "[0 1 1 0 1 0 1 1 0]: 214\n",
      "==============================\n",
      "[1 1 1 0 0 1 0 0]: 228\n",
      "[1 0 1 1 1 0 0 1]: 185\n",
      "[1 1 0 0 1 1 1 0 1]: 413\n",
      "==============================\n",
      "[1 0 0 0 0 1 0 0]: 132\n",
      "[0 1 0 1 0 0 1 0]: 82\n",
      "[0 1 1 0 0 0 1 1 0]: 198\n",
      "==============================\n",
      "[1 0 0 0 1 0 0 1]: 137\n",
      "[1 1 1 1 0 1 0 1]: 245\n",
      "[1 0 1 1 1 1 0 1 0]: 378\n",
      "==============================\n",
      "[1 1 1 0 1 1 1 1]: 239\n",
      "[1 1 1 1 0 0 1 1]: 243\n",
      "[1 1 1 0 1 0 0 1 0]: 466\n",
      "==============================\n",
      "[1 0 0 1 0 0 0 1]: 145\n",
      "[0 0 1 0 1 1 1 0]: 46\n",
      "[0 1 0 1 1 0 1 1 1]: 183\n",
      "==============================\n",
      "[1 1 0 1 0 0 1 0]: 210\n",
      "[1 0 0 1 1 1 1 1]: 159\n",
      "[1 0 1 1 1 1 1 0 1]: 381\n",
      "==============================\n",
      "[0 0 1 1 1 1 0 1]: 61\n",
      "[1 0 0 1 1 1 0 0]: 156\n",
      "[0 1 1 0 1 0 1 1 1]: 215\n",
      "==============================\n",
      "[0 1 0 1 1 0 1 1]: 91\n",
      "[0 0 0 0 0 0 1 1]: 3\n",
      "[0 0 1 0 1 0 1 1 0]: 86\n",
      "==============================\n",
      "[1 0 1 1 1 0 0 0]: 184\n",
      "[0 0 1 1 0 1 0 1]: 53\n",
      "[0 1 1 1 1 0 1 0 1]: 245\n",
      "==============================\n",
      "[1 1 1 1 0 0 0 1]: 241\n",
      "[1 1 0 1 0 0 1 0]: 210\n",
      "[1 1 0 1 1 0 1 0 1]: 437\n",
      "==============================\n",
      "[1 1 1 0 1 0 0 0]: 232\n",
      "[1 1 1 0 1 0 0 1]: 233\n",
      "[1 1 1 1 1 0 0 0 1]: 497\n",
      "==============================\n",
      "[1 0 0 1 0 0 1 1]: 147\n",
      "[1 0 0 0 0 0 1 0]: 130\n",
      "[1 0 0 0 0 0 1 0 1]: 261\n",
      "==============================\n",
      "[0 0 1 0 1 0 0 1]: 41\n",
      "[0 0 1 0 0 1 1 1]: 39\n",
      "[0 0 1 0 1 1 0 1 0]: 90\n",
      "==============================\n",
      "[1 0 0 1 0 1 0 0]: 148\n",
      "[1 1 0 0 0 1 0 1]: 197\n",
      "[1 0 1 0 1 0 0 0 1]: 337\n",
      "==============================\n",
      "[0 0 0 1 1 0 1 0]: 26\n",
      "[1 0 1 0 1 0 0 1]: 169\n",
      "[0 1 0 1 1 1 0 1 1]: 187\n",
      "==============================\n",
      "[1 0 1 1 0 0 0 1]: 177\n",
      "[0 0 1 0 1 1 1 1]: 47\n",
      "[0 1 1 0 0 0 0 1 0]: 194\n",
      "==============================\n",
      "[0 0 0 1 0 1 0 1]: 21\n",
      "[0 0 0 1 0 1 1 0]: 22\n",
      "[0 0 0 1 1 1 1 0 1]: 61\n",
      "==============================\n",
      "[0 0 1 1 0 0 0 0]: 48\n",
      "[0 1 1 1 0 0 1 0]: 114\n",
      "[0 1 0 1 1 0 0 1 0]: 178\n",
      "==============================\n",
      "[0 1 1 0 0 1 1 1]: 103\n",
      "[0 1 0 0 1 1 0 1]: 77\n",
      "[0 1 0 1 1 0 1 0 0]: 180\n",
      "==============================\n",
      "[1 0 1 1 1 1 1 1]: 191\n",
      "[1 1 1 0 0 0 1 0]: 226\n",
      "[1 1 0 0 1 1 0 1 1]: 411\n",
      "==============================\n",
      "[0 1 0 0 1 1 0 1]: 77\n",
      "[0 1 1 0 0 1 1 0]: 102\n",
      "[0 1 0 1 1 0 1 1 1]: 183\n",
      "==============================\n",
      "[1 1 1 1 1 0 1 1]: 251\n",
      "[1 1 1 0 0 1 0 0]: 228\n",
      "[1 1 1 0 0 0 1 1 1]: 455\n",
      "==============================\n",
      "[0 0 0 1 0 1 1 0]: 22\n",
      "[1 0 1 1 0 0 0 0]: 176\n",
      "[0 1 1 0 1 1 0 1 0]: 218\n",
      "==============================\n",
      "[0 0 0 0 0 1 1 1]: 7\n",
      "[1 0 1 0 0 0 1 0]: 162\n",
      "[0 1 0 1 0 1 1 1 1]: 175\n",
      "==============================\n",
      "[0 1 0 0 1 1 1 1]: 79\n",
      "[1 1 0 0 0 0 0 1]: 193\n",
      "[1 0 0 0 1 0 0 0 0]: 272\n",
      "==============================\n",
      "[1 1 1 1 0 0 1 1]: 243\n",
      "[0 1 1 1 0 0 1 0]: 114\n",
      "[1 0 1 0 0 1 0 1 1]: 331\n",
      "==============================\n",
      "[1 1 0 1 0 0 1 1]: 211\n",
      "[0 1 0 0 1 1 0 0]: 76\n",
      "[1 0 0 0 1 0 0 0 1]: 273\n",
      "==============================\n",
      "[0 0 1 0 0 1 0 1]: 37\n",
      "[1 0 1 1 1 1 1 1]: 191\n",
      "[0 1 1 1 1 0 1 0 0]: 244\n",
      "==============================\n",
      "[1 1 1 0 0 1 1 1]: 231\n",
      "[0 0 0 1 1 0 1 0]: 26\n",
      "[0 1 1 1 1 0 1 0 1]: 245\n",
      "==============================\n",
      "[1 1 0 1 1 1 1 0]: 222\n",
      "[1 0 0 1 0 0 1 1]: 147\n",
      "[1 0 1 1 1 1 1 0 1]: 381\n",
      "==============================\n",
      "[0 1 1 1 1 1 0 0]: 124\n",
      "[1 1 1 0 1 1 0 0]: 236\n",
      "[1 0 1 1 1 0 0 0 0]: 368\n",
      "==============================\n",
      "[0 1 0 1 1 0 0 1]: 89\n",
      "[0 0 0 1 0 1 1 1]: 23\n",
      "[0 0 1 1 1 1 0 1 0]: 122\n",
      "==============================\n",
      "[1 0 1 0 0 0 0 1]: 161\n",
      "[1 0 1 0 1 0 1 0]: 170\n",
      "[1 0 1 0 0 1 0 0 1]: 329\n",
      "==============================\n",
      "[1 0 0 1 0 0 1 0]: 146\n",
      "[1 0 1 0 0 0 0 1]: 161\n",
      "[1 0 0 1 1 0 1 1 1]: 311\n",
      "==============================\n",
      "[1 0 1 1 1 1 0 1]: 189\n",
      "[1 0 1 1 0 1 0 1]: 181\n",
      "[1 0 1 1 1 1 0 1 0]: 378\n",
      "==============================\n",
      "[0 0 0 0 1 1 0 1]: 13\n",
      "[1 1 0 0 1 1 0 0]: 204\n",
      "[0 1 1 0 1 1 1 1 1]: 223\n",
      "==============================\n",
      "[1 1 0 1 1 1 1 0]: 222\n",
      "[1 1 1 1 0 0 1 0]: 242\n",
      "[1 1 0 1 1 1 1 0 0]: 444\n",
      "==============================\n",
      "[1 0 0 1 1 0 1 1]: 155\n",
      "[0 1 1 1 1 0 1 0]: 122\n",
      "[1 0 0 0 1 0 1 0 1]: 277\n",
      "==============================\n",
      "[1 1 0 0 0 1 0 1]: 197\n",
      "[1 1 1 1 1 0 1 1]: 251\n",
      "[1 1 0 1 1 1 0 0 0]: 440\n",
      "==============================\n",
      "[1 0 1 1 0 1 0 0]: 180\n",
      "[1 1 0 1 0 1 1 0]: 214\n",
      "[1 1 0 0 1 0 0 1 0]: 402\n",
      "==============================\n",
      "[0 0 0 0 1 0 1 0]: 10\n",
      "[1 1 0 0 0 0 1 1]: 195\n",
      "[0 1 1 0 1 1 1 0 1]: 221\n",
      "==============================\n",
      "[0 1 0 0 1 0 1 0]: 74\n",
      "[1 1 0 1 0 0 1 0]: 210\n",
      "[1 0 0 0 1 0 1 0 0]: 276\n",
      "==============================\n",
      "[0 0 1 1 1 1 1 0]: 62\n",
      "[0 1 0 0 1 0 0 1]: 73\n",
      "[0 1 0 0 1 1 1 1 1]: 159\n",
      "==============================\n",
      "[0 0 0 0 0 1 0 1]: 5\n",
      "[1 0 0 1 1 0 0 1]: 153\n",
      "[0 1 0 0 1 1 1 1 0]: 158\n",
      "==============================\n",
      "[1 1 0 0 0 1 0 1]: 197\n",
      "[1 1 0 1 0 0 0 1]: 209\n",
      "[1 1 0 0 0 1 0 1 0]: 394\n",
      "==============================\n",
      "[0 1 1 1 0 0 1 0]: 114\n",
      "[1 1 0 1 0 0 1 1]: 211\n",
      "[1 0 1 0 1 0 1 0 1]: 341\n",
      "==============================\n",
      "[0 1 1 0 1 0 1 0]: 106\n",
      "[1 0 1 1 0 0 0 0]: 176\n",
      "[1 0 0 0 0 0 1 1 0]: 262\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    start = np.random.randint(0, len(dataX)-1)\n",
    "    # print(dataX[start])\n",
    "    number1 = dataX[start][0:BINARY_DIM]\n",
    "    number2 = dataX[start][BINARY_DIM:]\n",
    "    print('='*30)\n",
    "    print('%s: %s'%(number1, binary2int(number1)))\n",
    "    print('%s: %s'%(number2, binary2int(number2)))\n",
    "    sample = np.reshape(X[start], (1, 2*BINARY_DIM, 1))\n",
    "    predict = np.round(model.predict(sample), 0).astype(np.int32)[0]\n",
    "    print('%s: %s'%(predict, binary2int(predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
